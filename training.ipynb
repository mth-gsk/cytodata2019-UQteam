{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16, resnet\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# n_chan = 2\n",
    "# model = vgg16.VGG16(input_shape=[201, 201, n_chan], classes=17, weights=None)\n",
    "# model = resnet.ResNet50(input_shape=[201, 201, n_chan], classes=17, weights=None)\n",
    "\n",
    "n_chan = 3\n",
    "model_pre = vgg16.VGG16(input_shape=[201, 201, n_chan], include_top=False, weights='imagenet')\n",
    "for layer in model_pre.layers:\n",
    "    layer.trainable = False\n",
    "layer = model_pre.output\n",
    "layer = Flatten()(layer)\n",
    "layer = Dense(4096, activation=\"relu\")(layer)\n",
    "layer = Dense(4096, activation=\"relu\")(layer)\n",
    "new_output = Dense(17, activation=\"softmax\")(layer)\n",
    "model = Model(inputs=model_pre.input, outputs=new_output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "def f1(actual, predicted):\n",
    "    predicted = tf.one_hot(tf.math.argmax(predicted, axis=1), depth=17)\n",
    "    TP = tf.math.count_nonzero(predicted * actual)\n",
    "    TN = tf.math.count_nonzero((predicted - 1) * (actual - 1))\n",
    "    FP = tf.math.count_nonzero(predicted * (actual - 1))\n",
    "    FN = tf.math.count_nonzero((predicted - 1) * actual)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score\n",
    "model.compile(loss='categorical_crossentropy', metrics=[f1], optimizer=Adam(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataGenerator import DataGenerator, TestDataGenerator\n",
    "from personal_data import location_data\n",
    "dataGenerator_train = DataGenerator(location_data, n_channels=n_chan, batch_size=128, normalize_data=2)\n",
    "dataGenerator_val = DataGenerator(location_data, n_channels=n_chan, batch_size=128, normalize_data=2, isTrainingData=False)\n",
    "dataGenerator_test = TestDataGenerator('../validation', n_channels=n_chan, batch_size=128, normalize_data=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "import time\n",
    "\n",
    "# tensorboard --logdir ~/cytodata2019/tensorboard &\n",
    "tensorboard = callbacks.TensorBoard(update_freq='batch',\n",
    "    log_dir='../tensorboard/' + time.strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(dataGenerator_train.generate(),\n",
    "    validation_data=dataGenerator_val.generate(),\n",
    "    steps_per_epoch=len(dataGenerator_train),\n",
    "    validation_steps=len(dataGenerator_val),\n",
    "    callbacks=[tensorboard], verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(dataGenerator_test.generate(), steps=len(dataGenerator_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hit_indices = np.argmax(predictions, axis=1).astype(dtype=np.int)\n",
    "hit_names = [dataGenerator_train.labelsNames[i] for i in hit_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names = [s[-15:-5] for s in dataGenerator_test.allData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cell_names), len(hit_names))\n",
    "with open('output.csv', 'w') as file:\n",
    "    file.write(\"cell_code,prediction\\n\")\n",
    "    for (c,h) in zip(cell_names, hit_names):\n",
    "        file.write(f\"{c},{h}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "(img1, type1) = next(dataGenerator_train.generate())\n",
    "(img2, type2) = next(dataGenerator_train.generate())\n",
    "class1 = np.argmax(type1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "imgsubset1 = img1[class1==5]\n",
    "plt.imshow(imgsubset1[1,:,:,1])"
   ]
  }
 ]
}